import sys
import os
from os import path as o
sys.path.append(o.abspath(o.join(o.dirname(sys.modules[__name__].__file__), "../..")))

from tqdm.auto import trange
import torch
from torch.utils.data import DataLoader
from torch.nn import CrossEntropyLoss
from momonet.momonet import MoMoNet
from momonet.encoders import LSTMEncoder
from momonet.decoders import LogisticDecoder
from datasets.titanic import TitanicDataset
from momonet.history import MoMoNetHistory
from pipelines import utils
import torch.nn.functional as F
import pickle as pkl

def main():
    PIPELINE_NAME = utils.extract_pipeline_name(sys.argv[0])
    print('Running Ì£{}...'.format(utils.get_display_name(PIPELINE_NAME)))
    args = utils.parse_args()

    torch.manual_seed(args.seed)

    features = ['Fare', 'Pclass', 'Age', 'Sex_male', 'Relatives', 'Embarked']
    targets = ['Survived']

    # Training / Validation / Testing ratios
    datasplit = (0.8, 0.2, 0)
    target_idx_to_balance = 0 # Balance 'Survived' during split
    
    # Batch size: set 0 for full batch
    batch_size = 32

    # Representation state size
    state_size = 1

    learning_rate = 0.01
    epochs = 300 if not args.epoch else args.epoch

    ##############################################################################
    ###### Create dataset and data loaders
    ##############################################################################
    dataset = TitanicDataset(
        features,
        targets,
        dropna=True,
        std=True
    ).partition_dataset()

    train_data, val_data, test_data = dataset.random_split(datasplit, args.seed, target_idx_to_balance)

    if batch_size == 0:
        batch_size_train = len(train_data)
        batch_size_val = len(val_data)
        batch_size_test = len(test_data)
    else:
        batch_size_train = batch_size
        batch_size_val = batch_size
        batch_size_test = batch_size

    train_loader = DataLoader(train_data, batch_size_train)
    val_loader = DataLoader(val_data, batch_size_val)

    ##############################################################################
    ###### Set encoder and decoders
    ##############################################################################
    encoders = [LSTMEncoder(state_size, len(features), (5, 5), F.relu)]
    decoders = [LogisticDecoder(state_size) for _ in targets]

    model = MoMoNet(state_size, encoders, decoders, 0.7, 0.3)

    optimizer = torch.optim.Adam(list(model.parameters()), learning_rate)

    criterion = CrossEntropyLoss()

    history = MoMoNetHistory(targets)

    ##############################################################################
    ###### Train and Test model
    ##############################################################################
    for _ in trange(epochs):
        model.train_epoch(train_loader, optimizer, criterion, history)
        model.test(val_loader, criterion, history, tag='val')

    ##############################################################################
    ###### Store model and history
    ##############################################################################
    directory = o.join(o.dirname(os.path.realpath(__file__)), 'models')

    if args.save_model:
        if not o.exists(directory):
            os.makedirs(directory)
        model_path = o.join(directory, PIPELINE_NAME + '_model.pkl')
        pkl.dump(model, open(model_path, 'wb'))

    if args.save_history:
        if not o.exists(directory):
            os.makedirs(directory)
        history_path = o.join(directory, PIPELINE_NAME + '_history.pkl')
        pkl.dump(history, open(history_path, 'wb'))

    ##############################################################################
    ###### Save learning curves
    ##############################################################################
    if args.save_plot:
        directory = o.join(o.dirname(os.path.realpath(__file__)), 'plots')
        if not o.exists(directory):
            os.makedirs(directory)
        plot_path = o.join(directory, PIPELINE_NAME + '.png')

        targets_to_display = targets

        history.plot(plot_path, targets_to_display, show_state_change=False)

    ##############################################################################
    ###### Display results and save them
    ##############################################################################
    if args.save_results:
        directory = o.join(o.dirname(os.path.realpath(__file__)), 'results')
        if not o.exists(directory):
            os.makedirs(directory)
        results_path = o.join(directory, PIPELINE_NAME + '.csv')

        history.print_results()
        history.save_results(results_path)

if __name__ == "__main__":
    main()
